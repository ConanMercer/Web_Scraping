{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('base': conda)",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9a443516413c2881eaa45503843a41caec010d6420f7e7f4b04a65c7fd85d327"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Data Scraping\n",
    "Data scraping is a technique in which a computer program extracts data from human-readable output coming from another program.\n",
    "\n",
    "Beautiful Soup (called bs4 when calling the package in Python) is a Python package for parsing HTML and XML documents. This will be used to extract data from HTML pages.\n",
    "Urllib is a Python package that collects several modules for working with URLs:\n",
    "* request\n",
    "* error\n",
    "* parse\n",
    "* robot parser\n",
    "\n",
    "The following code block loads these packages and imports BeautifulSoup as soup, which means that we can use \"soup\" when calling BeautifulSoup functions instead of \"BeautifulSoup\" to simplify the code somewhat. Also, urllib as \"uReq\" because the code is only importing the request module."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup  # Library for HTML data structures\n",
    "from urllib.request import urlopen as uReq  # Library for opening URLs\n",
    "import re # Library for regular expressions"
   ]
  },
  {
   "source": [
    "Next a variable is created to store the website URL of interest. The example used here is lifeinformatica.com for computer central processing unit (CPUs) products:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_url = \"https://lifeinformatica.com/categoria-producto/family-componentes/family-procesadores/\""
   ]
  },
  {
   "source": [
    "Next the connection is opened and the HTML page from the URl is downloaded:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uClient = uReq(page_url)"
   ]
  },
  {
   "source": [
    "Next the html is parsed into a soup data structure. This will allow navigation through the HTML data in a way similar to json data type. After, the connection is closed to the URL:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_soup = soup(uClient.read(), \"html.parser\")\n",
    "uClient.close()"
   ]
  },
  {
   "source": [
    "page_soup now holds all the HTML data from the URL. The data of interest is each CPU product, specifically the name, brand, speed and price. The other infomation contained within the HTML is not of importance to the project right now. By navigating through the HTML structure, it is possible to find the class that holds the data for each CPU product:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "containers = page_soup.findAll(\"div\", {\"class\": \"product-inner product-item__inner\"})"
   ]
  },
  {
   "source": [
    "Next, the out_filename is a variable that stores the name of the output file in csv format. The headers variable is used to write to local disk and header of csv file to be written."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_filename = \"cpu.csv\"\n",
    "headers = \"manufacturer,product_name,speed,price \\n\"\n"
   ]
  },
  {
   "source": [
    "Next the file is opened and the headers are written to the file. The \"w\" parameter overwrites any existing content:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "f = open(out_filename, \"w\")\n",
    "f.write(headers)"
   ]
  },
  {
   "source": [
    "Next the actual data extraction from the HTML structure. The data needed is the Manufacturer, Product Name, Speed of the CPU, and the Price.\n",
    "Idealy, the HTML structure would be constructed in a way that all the data needed is already seperated into elements. This is not the case for this website. Here, the data can be extracted by first finding the parts needed. Most of the parts are in the title of each container. From here strings can be used to carefully pull out the data parts that are needed, in a systematic apporach, meaning that it works well for all the CPU products in the webpage."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "manufacturer: AMD\n\nproduct_name:  Ryzen 5 3400G \n\nspeed: 4.2 \n\nprice: 139,90\n\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0aaad6dad905>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mspeed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_title\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mspeed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'([^x]+)'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mspeed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#Product Name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "for container in containers:\n",
    "\n",
    "    element = container.findAll(\"h2\", {\"class\": \"woocommerce-loop-product__title\"})[0]\n",
    "\n",
    "    #Manufacturer\n",
    "    manufacturer = element.text.split(' ', 1)[0]\n",
    "\n",
    "    #Speed\n",
    "    full_title = element.text \n",
    "    split_word = 'GHz'   \n",
    "    if manufacturer == \"AMD\":\n",
    "        speed = full_title.partition(split_word)[0].split(' ', 4)[4]\n",
    "    else:\n",
    "        speed = re.search('([^x]+)'+speed, split_word).group(1)\n",
    "\n",
    "    #Product Name\n",
    "    if manufacturer == \"AMD\":\n",
    "        product_name = re.search(manufacturer+'(.*?)'+speed, full_title).group(1)\n",
    "    else:\n",
    "        product_name = re.search(manufacturer+'(.*?)'+speed, full_title).group(1)\n",
    "\n",
    "    #Price\n",
    "    price = container.findAll(\"span\", {\"class\": \"woocommerce-Price-amount amount\"})[0].text.strip().replace(\"â‚¬\", \"\")\n",
    "\n",
    "    print(\"manufacturer: \" + manufacturer + \"\\n\")\n",
    "    print(\"product_name: \" + product_name + \"\\n\")\n",
    "    print(\"speed: \" + speed + \"\\n\")\n",
    "    print(\"price: \" + price + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}