{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('base': conda)",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9a443516413c2881eaa45503843a41caec010d6420f7e7f4b04a65c7fd85d327"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Data Scraping\n",
    "Data scraping is a technique in which a computer program extracts data from human-readable output coming from another program.\n",
    "\n",
    "Beautiful Soup (called bs4 when calling the package in Python) is a Python package for parsing HTML and XML documents. This will be used to extract data from HTML pages.\n",
    "Urllib is a Python package that collects several modules for working with URLs:\n",
    "* request\n",
    "* error\n",
    "* parse\n",
    "* robot parser\n",
    "\n",
    "The following code block loads these packages and imports BeautifulSoup as soup, which means that we can use \"soup\" when calling BeautifulSoup functions instead of \"BeautifulSoup\" to simplify the code somewhat. Also, urllib as \"uReq\" because the code is only importing the request module."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup  # Library for HTML data structures\n",
    "from urllib.request import urlopen as uReq  # Library for opening URLs"
   ]
  },
  {
   "source": [
    "Next a variable is created to store the website URL of interest. The example used here is lifeinformatica.com for computer central processing unit (CPUs) products:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_url = \"https://lifeinformatica.com/categoria-producto/family-componentes/family-procesadores/\""
   ]
  },
  {
   "source": [
    "Next the connection is opened and the HTML page from the URl is downloaded:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uClient = uReq(page_url)"
   ]
  },
  {
   "source": [
    "Next the html is parsed into a soup data structure. This will allow navigation through the HTML data in a way similar to json data type. After, the connection is closed to the URL:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_soup = soup(uClient.read(), \"html.parser\")\n",
    "uClient.close()"
   ]
  },
  {
   "source": [
    "page_soup now holds all the HTML data from the URL. The data of interest is each CPU product, specifically the name, brand, speed and price. The other infomation contained within the HTML is not of importance to the project right now. By navigating through the HTML structure, it is possible to find the class that holds the data for each CPU product:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "containers = page_soup.findAll(\"div\", {\"class\": \"product-inner product-item__inner\"})"
   ]
  },
  {
   "source": [
    "Next, the out_filename is a variable that stores the name of the output file in csv format. The headers variable is used to write to local disk and header of csv file to be written."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_filename = \"cpu.csv\"\n",
    "headers = \"brand,product_name,speed,price \\n\"\n"
   ]
  }
 ]
}